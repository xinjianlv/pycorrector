




python -m main.py  --bert_model bert-base-uncased  --do_lower_case  --do_train  --train_file ./samples/sample_text.txt  --output_dir ./samples/samples_out  --max_seq_length 128 --train_batch_size 16  --learning_rate 3e-5  --num_train_epochs 1.0


python -m run_lm_finetuning  --bert_model ./my_test/data/student/part1.txt  --do_lower_case  --do_train  --train_file ./samples/sample_text.txt  --output_dir ./samples/samples_out  --max_seq_length 128 --train_batch_size 16  --learning_rate 3e-5  --num_train_epochs 1.0
